{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fee1de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('StudentsPerformance.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eaac321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>female</td>\n",
       "      <td>group E</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender race/ethnicity parental level of education         lunch  \\\n",
       "995  female        group E             master's degree      standard   \n",
       "996    male        group C                 high school  free/reduced   \n",
       "997  female        group C                 high school  free/reduced   \n",
       "998  female        group D                some college      standard   \n",
       "999  female        group D                some college  free/reduced   \n",
       "\n",
       "    test preparation course  math score  reading score  writing score  \n",
       "995               completed          88             99             95  \n",
       "996                    none          62             55             55  \n",
       "997               completed          59             71             65  \n",
       "998               completed          68             78             77  \n",
       "999                    none          77             86             86  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bccd8b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gender                       1000 non-null   object\n",
      " 1   race/ethnicity               1000 non-null   object\n",
      " 2   parental level of education  1000 non-null   object\n",
      " 3   lunch                        1000 non-null   object\n",
      " 4   test preparation course      1000 non-null   object\n",
      " 5   math score                   1000 non-null   int64 \n",
      " 6   reading score                1000 non-null   int64 \n",
      " 7   writing score                1000 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960df304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.08900</td>\n",
       "      <td>69.169000</td>\n",
       "      <td>68.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.16308</td>\n",
       "      <td>14.600192</td>\n",
       "      <td>15.195657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.00000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>57.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.00000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       math score  reading score  writing score\n",
       "count  1000.00000    1000.000000    1000.000000\n",
       "mean     66.08900      69.169000      68.054000\n",
       "std      15.16308      14.600192      15.195657\n",
       "min       0.00000      17.000000      10.000000\n",
       "25%      57.00000      59.000000      57.750000\n",
       "50%      66.00000      70.000000      69.000000\n",
       "75%      77.00000      79.000000      79.000000\n",
       "max     100.00000     100.000000     100.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7010cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                         0\n",
       "race/ethnicity                 0\n",
       "parental level of education    0\n",
       "lunch                          0\n",
       "test preparation course        0\n",
       "math score                     0\n",
       "reading score                  0\n",
       "writing score                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking missing values\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "317e6014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "female    518\n",
       "male      482\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c8478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   gender                       1000 non-null   object \n",
      " 1   race/ethnicity               1000 non-null   object \n",
      " 2   parental level of education  1000 non-null   object \n",
      " 3   lunch                        1000 non-null   object \n",
      " 4   test preparation course      1000 non-null   object \n",
      " 5   average_score                1000 non-null   float64\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Create lables\n",
    "\n",
    "# 1. For regression\n",
    "\n",
    "df['average_score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)\n",
    "df.drop(['math score', 'reading score', 'writing score'], axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ac5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   gender                       1000 non-null   object \n",
      " 1   race/ethnicity               1000 non-null   object \n",
      " 2   parental level of education  1000 non-null   object \n",
      " 3   lunch                        1000 non-null   object \n",
      " 4   test preparation course      1000 non-null   object \n",
      " 5   average_score                1000 non-null   float64\n",
      " 6   pass                         1000 non-null   int32  \n",
      "dtypes: float64(1), int32(1), object(5)\n",
      "memory usage: 50.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2. For classification\n",
    "df[\"pass\"] = (df[\"average_score\"] >= 50).astype(int)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c8d9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting into x and y  for regression\n",
    "X = df.drop([\"average_score\", \"pass\"], axis=1)\n",
    "y_lin = df[\"average_score\"]\n",
    "y_class = df[\"pass\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc3c620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRain- Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_lin_train, X_lin_test, y_lin_train, y_lin_test = train_test_split(X, y_lin, test_size=0.3, random_state=42)\n",
    "\n",
    "X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X, y_class, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe8364d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulding pipline \n",
    "char_fetures = X.select_dtypes(include=['object', 'string']).columns\n",
    "num_fetures = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "char_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# combine them \n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_fetures),\n",
    "    ('char', char_pipeline, char_fetures)\n",
    "])\n",
    "\n",
    "X_lin_test_prepared = full_pipeline.fit_transform(X_lin_test)\n",
    "X_lin_train_prepared = full_pipeline.fit_transform(X_lin_train)\n",
    "\n",
    "X_class_train_prepared = full_pipeline.fit_transform(X_class_train)\n",
    "X_class_test_train = full_pipeline.fit_transform(X_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5bb8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "# 1. regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_lin_train_prepared, y_lin_train)\n",
    "\n",
    "y_lin_pred = reg_model.predict(X_lin_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f77e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 13.27\n",
      "MAE: 10.57\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Regression Model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "mse_lin = mean_squared_error(y_lin_test, y_lin_pred)\n",
    "rmse_lin = np.sqrt(mse)\n",
    "mae_lin = mean_absolute_error(y_lin_test, y_lin_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse_lin:.2f}\")\n",
    "print(f\"MAE: {mae_lin:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbc651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-validation scores: [nan nan nan nan nan]\n",
      "Mean Accuracy: nan\n",
      "Standard Deviation: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# For regression\n",
    "scores = cross_val_score(reg_model, X_lin_train_prepared, y_lin_train, cv=5, scoring=\"accuracy\") # type: ignore\n",
    "print('\\n')\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e64b0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifications \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_class_train_prepared, y_class_train) \n",
    "y_class_pred = clf.predict(X_class_test_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d69ae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  43]\n",
      " [  0 257]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        43\n",
      "           1       0.86      1.00      0.92       257\n",
      "\n",
      "    accuracy                           0.86       300\n",
      "   macro avg       0.43      0.50      0.46       300\n",
      "weighted avg       0.73      0.86      0.79       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_class_test, y_class_pred))\n",
    "print(classification_report(y_class_test, y_class_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.91428571 0.91428571 0.91428571 0.91428571 0.91428571]\n",
      "Mean Accuracy: 0.9142857142857143\n",
      "Standard Deviation: 0.0\n",
      "\n",
      "\n",
      "Cross-validation scores: [nan nan nan nan nan]\n",
      "Mean Accuracy: nan\n",
      "Standard Deviation: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yuvra\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 123, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# For regression\n",
    "scores = cross_val_score(reg_model, X_lin_train_prepared, y_lin_train, cv=5, scoring=\"accuracy\")\n",
    "print('\\n')\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())\n",
    "# For classifier\n",
    "scores = cross_val_score(clf, X_class_train_prepared, y_class_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de032e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
